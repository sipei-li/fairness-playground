{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from scipy import sparse\n",
    "\n",
    "import random\n",
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', header=None, sep='::', \n",
    "                      encoding='latin-1', engine='python', \n",
    "                      names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "users = pd.read_csv('ml-1m/users.dat', header=None, sep='::',\n",
    "                    encoding='latin-1', engine='python',\n",
    "                    names=['user_id', 'gender', 'age', 'occupation', 'zipcode'])\n",
    "movies = pd.read_csv('ml-1m/movies.dat', header=None, sep='::',\n",
    "                     encoding='latin-1', engine='python',\n",
    "                     names=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['user_id'] = ratings['user_id'] - 1\n",
    "ratings['movie_id'] = ratings['movie_id'] - 1\n",
    "users['user_id'] = users['user_id'] - 1\n",
    "movies['movie_id'] = movies['movie_id'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1192</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>660</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3407</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2354</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        0      1192       5  978300760\n",
       "1        0       660       3  978302109\n",
       "2        0       913       3  978301968\n",
       "3        0      3407       4  978300275\n",
       "4        0      2354       5  978824291"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000209, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 6040\n",
      "Number of items: 3883\n"
     ]
    }
   ],
   "source": [
    "user_n = ratings['user_id'].nunique()\n",
    "item_n = movies['movie_id'].nunique()\n",
    "print(\"Number of users: {}\".format(user_n))\n",
    "print(\"Number of items: {}\".format(item_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_iid = {movies['movie_id'][i]:i for i in movies.index}\n",
    "iid_to_id = {i:movies['movie_id'][i] for i in movies.index}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genre popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama          1603\n",
       "Comedy         1200\n",
       "Action          503\n",
       "Thriller        492\n",
       "Romance         471\n",
       "Horror          343\n",
       "Adventure       283\n",
       "Sci-Fi          276\n",
       "Children's      251\n",
       "Crime           211\n",
       "War             143\n",
       "Documentary     127\n",
       "Musical         114\n",
       "Mystery         106\n",
       "Animation       105\n",
       "Fantasy          68\n",
       "Western          68\n",
       "Film-Noir        44\n",
       "Name: genres, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.genres.str.split('|').explode().value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Movie Feature Vectors From Genre Information\n",
    "\n",
    "Use tf-idf, a weighted frequecy, of each genre word as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf =  TfidfVectorizer(analyzer=lambda x: (c for i in range(1, 4) for c in combinations(x.split('|'), r=i)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vectorizer transforms a movie's genre description into a list of tokens, where each token is a subsequence of the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Action',),\n",
       " ('Crime',),\n",
       " ('Drama',),\n",
       " ('Action', 'Crime'),\n",
       " ('Action', 'Drama'),\n",
       " ('Crime', 'Drama'),\n",
       " ('Action', 'Crime', 'Drama')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = tf.build_analyzer()\n",
    "[token for token in analyzer('Action|Crime|Drama')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the weighted frequency of each token and form the feature vector of this movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 353)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf = tf.fit_transform(movies['genres'])\n",
    "X_tfidf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3883 movies, each has a feature vector of length 353 (which is the number of combinations of all the possible genres). Some of the movies are not in the dataset.\n",
    "\n",
    "## Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>Edge, The (1997)</th>\n",
       "      <th>Metroland (1997)</th>\n",
       "      <th>Man with the Golden Gun, The (1974)</th>\n",
       "      <th>From the Journals of Jean Seberg (1995)</th>\n",
       "      <th>Newsies (1992)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Six Degrees of Separation (1993)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Under the Rainbow (1981)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relic, The (1997)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dead Calm (1989)</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steel Magnolias (1989)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "title                             Edge, The (1997)  Metroland (1997)  \\\n",
       "title                                                                  \n",
       "Six Degrees of Separation (1993)              0.00              0.39   \n",
       "Under the Rainbow (1981)                      0.00              0.45   \n",
       "Relic, The (1997)                             0.00              0.00   \n",
       "Dead Calm (1989)                              0.41              0.00   \n",
       "Steel Magnolias (1989)                        0.00              0.39   \n",
       "\n",
       "title                             Man with the Golden Gun, The (1974)  \\\n",
       "title                                                                   \n",
       "Six Degrees of Separation (1993)                                  0.0   \n",
       "Under the Rainbow (1981)                                          0.0   \n",
       "Relic, The (1997)                                                 0.0   \n",
       "Dead Calm (1989)                                                  0.0   \n",
       "Steel Magnolias (1989)                                            0.0   \n",
       "\n",
       "title                             From the Journals of Jean Seberg (1995)  \\\n",
       "title                                                                       \n",
       "Six Degrees of Separation (1993)                                      0.0   \n",
       "Under the Rainbow (1981)                                              0.0   \n",
       "Relic, The (1997)                                                     0.0   \n",
       "Dead Calm (1989)                                                      0.0   \n",
       "Steel Magnolias (1989)                                                0.0   \n",
       "\n",
       "title                             Newsies (1992)  \n",
       "title                                             \n",
       "Six Degrees of Separation (1993)             0.0  \n",
       "Under the Rainbow (1981)                     0.0  \n",
       "Relic, The (1997)                            0.0  \n",
       "Dead Calm (1989)                             0.0  \n",
       "Steel Magnolias (1989)                       0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df = pd.DataFrame(sim, index=movies['title'], columns=movies['title'])\n",
    "sim_df.sample(5, axis=0).sample(5, axis=1).round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(ratings, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800167, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_mat(df):\n",
    "    \"\"\"\n",
    "    Convert DataFrame to sparse matrix.\n",
    "\n",
    "    Arg:\n",
    "        df: DataFrame, ratings dataframe with user_id, movie_id and rating\n",
    "\n",
    "    Return:\n",
    "        mat: scipy.sparse.csr_matrix, sparse ratings matrix with rows being items and cols being users\n",
    "    \"\"\"\n",
    "    \n",
    "    mat = sparse.lil_matrix((item_n, user_n))\n",
    "    for _, row in df.iterrows():\n",
    "        user_id = int(row[0])\n",
    "        item_id = int(row[1])\n",
    "        item_iid = id_to_iid[item_id]\n",
    "        rating = row[2]\n",
    "        mat[item_iid, user_id] = rating\n",
    "    \n",
    "    return mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 6040)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_user_mat = df_to_mat(train_df)\n",
    "item_user_mat = item_user_mat.tocsr()\n",
    "sparse.save_npz('ml-1m/item_user_mat.npz', item_user_mat)\n",
    "item_user_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_user_mat = sparse.load_npz('ml-1m/item_user_mat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10, n_jobs=-1)\n",
    "# fit the sparse matrix to the k nearest neighbor model\n",
    "knn.fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, topk):\n",
    "    \n",
    "    rated_before = np.nonzero(item_user_mat[:, user_id])[0]\n",
    "\n",
    "    if rated_before.size > 0:\n",
    "        # the user has at least reviewed one item\n",
    "        raw_recommends = {}\n",
    "        for item_iid in rated_before:\n",
    "            distances, indices = knn.kneighbors(X_tfidf[item_iid], n_neighbors=topk+1)\n",
    "            sorted_pairs = sorted(list(zip(indices.squeeze().tolist(),\n",
    "                                           distances.squeeze().tolist())),\n",
    "                                  key=lambda x: x[1])[:0:-1]\n",
    "            raw_recommends[item_iid] = sorted_pairs\n",
    "        \n",
    "        # get the top 10 items\n",
    "        top_items = []\n",
    "        pos = 0\n",
    "        while True:\n",
    "            for item_iid in rated_before:\n",
    "                next_neighbor_iid = raw_recommends[item_iid][pos][0]\n",
    "                top_items.append(iid_to_id[next_neighbor_iid])\n",
    "                if len(top_items) > topk - 1:\n",
    "                    return (user_id, np.array(top_items))\n",
    "            \n",
    "            pos += 1\n",
    "    else:\n",
    "        # the user has no review\n",
    "        top_items = list(map(lambda x: iid_to_id[x], random.sample(list(range(0, item_n)), topk)))\n",
    "        return (user_id, np.array(top_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array([2077, 1281,  854,  315, 1207, 2058, 3775,  593,  593,  593],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(0, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make recommendations for all the users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\queue.py:167\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 167\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    168\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m user \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(user_n):\n\u001b[1;32m----> 3\u001b[0m     res\u001b[39m.\u001b[39mappend(recommend(user, \u001b[39m5\u001b[39;49m))\n\u001b[0;32m      4\u001b[0m user_recs_allinclude \u001b[39m=\u001b[39m {x[\u001b[39m0\u001b[39m]:x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m res}\n",
      "Cell \u001b[1;32mIn [27], line 9\u001b[0m, in \u001b[0;36mrecommend\u001b[1;34m(user_id, topk)\u001b[0m\n\u001b[0;32m      7\u001b[0m raw_recommends \u001b[39m=\u001b[39m {}\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m item_iid \u001b[39min\u001b[39;00m rated_before:\n\u001b[1;32m----> 9\u001b[0m     distances, indices \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mkneighbors(X_tfidf[item_iid], n_neighbors\u001b[39m=\u001b[39;49mtopk\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m     sorted_pairs \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(indices\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist(),\n\u001b[0;32m     11\u001b[0m                                    distances\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mtolist())),\n\u001b[0;32m     12\u001b[0m                           key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m])[:\u001b[39m0\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m     raw_recommends[item_iid] \u001b[39m=\u001b[39m sorted_pairs\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\sklearn\\neighbors\\_base.py:796\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 796\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[0;32m    797\u001b[0m         pairwise_distances_chunked(\n\u001b[0;32m    798\u001b[0m             X,\n\u001b[0;32m    799\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[0;32m    800\u001b[0m             reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[0;32m    801\u001b[0m             metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[0;32m    802\u001b[0m             n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    803\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[0;32m    804\u001b[0m         )\n\u001b[0;32m    805\u001b[0m     )\n\u001b[0;32m    807\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    808\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1849\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[1;32m-> 1850\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m   1851\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1852\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1854\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m   2020\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 2022\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1568\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1566\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n\u001b[0;32m   1567\u001b[0m ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1568\u001b[0m Parallel(backend\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreading\u001b[39;49m\u001b[39m\"\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49mn_jobs)(\n\u001b[0;32m   1569\u001b[0m     fd(func, ret, s, X, Y[s], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m gen_even_slices(_num_samples(Y), effective_n_jobs(n_jobs))\n\u001b[0;32m   1571\u001b[0m )\n\u001b[0;32m   1573\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m func \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1574\u001b[0m     \u001b[39m# zeroing diagonal for euclidean norm.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m     \u001b[39m# TODO: do it also for other norms.\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m     np\u001b[39m.\u001b[39mfill_diagonal(ret, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1569\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1566\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n\u001b[0;32m   1567\u001b[0m ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1568\u001b[0m Parallel(backend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthreading\u001b[39m\u001b[39m\"\u001b[39m, n_jobs\u001b[39m=\u001b[39mn_jobs)(\n\u001b[1;32m-> 1569\u001b[0m     fd(func, ret, s, X, Y[s], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m   1570\u001b[0m     \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m gen_even_slices(_num_samples(Y), effective_n_jobs(n_jobs))\n\u001b[0;32m   1571\u001b[0m )\n\u001b[0;32m   1573\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m func \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1574\u001b[0m     \u001b[39m# zeroing diagonal for euclidean norm.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m     \u001b[39m# TODO: do it also for other norms.\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m     np\u001b[39m.\u001b[39mfill_diagonal(ret, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\scipy\\sparse\\_index.py:69\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m row \u001b[39m==\u001b[39m \u001b[39mslice\u001b[39m(\u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m row \u001b[39m==\u001b[39m col:\n\u001b[0;32m     68\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 69\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_sliceXslice(row, col)\n\u001b[0;32m     70\u001b[0m \u001b[39melif\u001b[39;00m col\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sliceXarray(row, col)\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\scipy\\sparse\\_compressed.py:665\u001b[0m, in \u001b[0;36m_cs_matrix._get_sliceXslice\u001b[1;34m(self, row, col)\u001b[0m\n\u001b[0;32m    663\u001b[0m major, minor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap((row, col))\n\u001b[0;32m    664\u001b[0m \u001b[39mif\u001b[39;00m major\u001b[39m.\u001b[39mstep \u001b[39min\u001b[39;00m (\u001b[39m1\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m minor\u001b[39m.\u001b[39mstep \u001b[39min\u001b[39;00m (\u001b[39m1\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 665\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_submatrix(major, minor, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    666\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_major_slice(major)\u001b[39m.\u001b[39m_minor_slice(minor)\n",
      "File \u001b[1;32mc:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\scipy\\sparse\\_compressed.py:810\u001b[0m, in \u001b[0;36m_cs_matrix._get_submatrix\u001b[1;34m(self, major, minor, copy)\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[39mif\u001b[39;00m i0 \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m j0 \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i1 \u001b[39m==\u001b[39m M \u001b[39mand\u001b[39;00m j1 \u001b[39m==\u001b[39m N:\n\u001b[0;32m    808\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m copy \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m--> 810\u001b[0m indptr, indices, data \u001b[39m=\u001b[39m get_csr_submatrix(\n\u001b[0;32m    811\u001b[0m     M, N, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindptr, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, i0, i1, j0, j1)\n\u001b[0;32m    813\u001b[0m shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap((i1 \u001b[39m-\u001b[39m i0, j1 \u001b[39m-\u001b[39m j0))\n\u001b[0;32m    814\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m((data, indices, indptr), shape\u001b[39m=\u001b[39mshape,\n\u001b[0;32m    815\u001b[0m                       dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for user in range(user_n):\n",
    "    res.append(recommend(user, 5))\n",
    "user_recs_allinclude = {x[0]:x[1] for x in res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(user_recs_allinclude)\n",
    "df.to_csv('user_recs_allinclude_df.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# ground_truth: list of items ordered by time\n",
    "def nDCG_Time(ground_truth, _recList):\n",
    "    rec_num = len(_recList) # topK\n",
    "    # ground_truth is already sorted by time\n",
    "    idealOrder = ground_truth\n",
    "    idealDCG = 0.0\n",
    "    for j in range(min(rec_num, len(idealOrder))):\n",
    "        idealDCG += ((math.pow(2.0, len(idealOrder) - j) - 1) / math.log(2.0 + j))\n",
    "\n",
    "    recDCG = 0.0\n",
    "    for j in range(rec_num):\n",
    "        item = _recList[j]\n",
    "        if item in ground_truth:\n",
    "            rank = len(ground_truth) - ground_truth.index(item) # why ground truth?\n",
    "            recDCG += ((math.pow(2.0, rank) - 1) / math.log(1.0 + j + 1))\n",
    "\n",
    "    return (recDCG / idealDCG)\n",
    "\n",
    "\n",
    "def Recall(_test_set, _recList):\n",
    "    hit = len(set(_recList).intersection(set(_test_set)))\n",
    "    return hit / float(len(_test_set))\n",
    "\n",
    "\n",
    "def Precision(_test_set, _recList):\n",
    "    hit = len(set(_recList).intersection(set(_test_set)))\n",
    "    return hit / float(len(_recList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200042, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mat = df_to_mat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_users = users[users['gender'] == 'F']\n",
    "m_users=  users[users['gender'] == 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f_user_ids = f_users.sample(100)['user_id'].to_numpy()\n",
    "test_m_user_ids = m_users.sample(100)['user_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 100 randomly sampled female users:\n",
      " avg-precision: 0.005\n",
      " avg-recall: 0.003\n",
      " avg-nDCG: 0.000\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "p = []\n",
    "n = []\n",
    "\n",
    "for user_id in test_f_user_ids:\n",
    "    test_items_iids = list(np.argwhere(test_mat[:, user_id] >= 4)[:, 0])\n",
    "    test_items = list(map(lambda x: iid_to_id[x], test_items_iids))\n",
    "    \n",
    "    if len(test_items) > 0:\n",
    "        top_items = list(recommend(user_id, 10)[1])\n",
    "        \n",
    "        recall = Recall(test_items, top_items)\n",
    "        precision = Precision(test_items, top_items)\n",
    "        ndcg = nDCG_Time(test_items, top_items)\n",
    "\n",
    "        r.append(recall)\n",
    "        p.append(precision)\n",
    "        n.append(ndcg)\n",
    "\n",
    "print(\"For 100 randomly sampled female users:\")\n",
    "print(\" avg-precision: %.3f\\n avg-recall: %.3f\\n avg-nDCG: %.3f\" %\n",
    "       (np.average(p),np.average(r),np.average(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 100 randomly sampled male users:\n",
      " avg-precision: 0.008\n",
      " avg-recall: 0.005\n",
      " avg-nDCG: 0.006\n"
     ]
    }
   ],
   "source": [
    "r = []\n",
    "p = []\n",
    "n = []\n",
    "\n",
    "for user_id in test_m_user_ids:\n",
    "    test_items_iids = list(np.argwhere(test_mat[:, user_id] >= 4)[:, 0])\n",
    "    test_items = list(map(lambda x: iid_to_id[x], test_items_iids))\n",
    "    \n",
    "    if len(test_items) > 0:\n",
    "        top_items = list(recommend(user_id, 10)[1])\n",
    "        \n",
    "        recall = Recall(test_items, top_items)\n",
    "        precision = Precision(test_items, top_items)\n",
    "        ndcg = nDCG_Time(test_items, top_items)\n",
    "\n",
    "        r.append(recall)\n",
    "        p.append(precision)\n",
    "        n.append(ndcg)\n",
    "\n",
    "print(\"For 100 randomly sampled male users:\")\n",
    "print(\" avg-precision: %.3f\\n avg-recall: %.3f\\n avg-nDCG: %.3f\" %\n",
    "       (np.average(p),np.average(r),np.average(n)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a smaller tf-idf vectorizer for lda: only use genres for tokens, no combinations of genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tf =  TfidfVectorizer(analyzer=lambda x: (c for i in range(1, 2) for c in combinations(x.split('|'), r=i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Action',), ('Crime',), ('Sci-Fi',)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_analyzer = small_tf.build_analyzer()\n",
    "[token for token in small_analyzer('Action|Crime|Sci-Fi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 18)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_X_tfidf = small_tf.fit_transform(movies['genres'])\n",
    "small_X_tfidf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3883 movies with 18 token (genres) weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10) # 5 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lda = lda.fit_transform(small_X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 18)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of 20 tokens in 10 latent topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = small_tf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:  [('Romance',), ('Drama',), ('Action',), ('Adventure',)]\n",
      "Topic 1:  [('Comedy',), ('Drama',), ('Western',), ('Action',)]\n",
      "Topic 2:  [(\"Children's\",), ('Adventure',), ('Fantasy',), ('Comedy',)]\n",
      "Topic 3:  [('Romance',), ('Comedy',), ('Drama',), ('Musical',)]\n",
      "Topic 4:  [('Action',), ('Sci-Fi',), ('Adventure',), ('Thriller',)]\n",
      "Topic 5:  [('Thriller',), ('Crime',), ('Drama',), ('Action',)]\n",
      "Topic 6:  [('War',), ('Musical',), ('Drama',), ('Action',)]\n",
      "Topic 7:  [('Horror',), ('Sci-Fi',), ('Thriller',), ('Comedy',)]\n",
      "Topic 8:  [('Mystery',), ('Animation',), (\"Children's\",), ('Thriller',)]\n",
      "Topic 9:  [('Drama',), ('Documentary',), ('Western',), ('Comedy',)]\n"
     ]
    }
   ],
   "source": [
    "for i, weights in enumerate(lda.components_):\n",
    "    zipped = zip(genres, weights)\n",
    "    top_genres_key = sorted(zipped, key = lambda t: t[1], reverse=True)[:4]\n",
    "    top_genres_list = list(dict(top_genres_key).keys())\n",
    "    print(\"Topic \" + str(i) + \": \", top_genres_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f96e607b91a2e2d3251db7ddf844b8ed38c6c958a32172526e41c91f117aef26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
