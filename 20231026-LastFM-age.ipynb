{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import svds\n",
    "import implicit\n",
    "\n",
    "import random\n",
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# ground_truth: list of items ordered by time\n",
    "def nDCG_Time(ground_truth, _recList):\n",
    "    rec_num = len(_recList) # topK\n",
    "    # ground_truth is already sorted by time\n",
    "    idealOrder = ground_truth\n",
    "    idealDCG = 0.0\n",
    "    for j in range(min(rec_num, len(idealOrder))):\n",
    "        idealDCG += ((math.pow(2.0, len(idealOrder) - j) - 1) / math.log(2.0 + j))\n",
    "\n",
    "    recDCG = 0.0\n",
    "    for j in range(rec_num):\n",
    "        item = _recList[j]\n",
    "        if item in ground_truth:\n",
    "            rank = len(ground_truth) - ground_truth.index(item) # why ground truth?\n",
    "            recDCG += ((math.pow(2.0, rank) - 1) / math.log(1.0 + j + 1))\n",
    "\n",
    "    return (recDCG / idealDCG)\n",
    "\n",
    "\n",
    "def Recall(_test_set, _recList):\n",
    "    hit = len(set(_recList).intersection(set(_test_set)))\n",
    "    # return hit / float(len(_test_set))\n",
    "    return hit / min(float(len(_test_set)), float(len(_recList)))\n",
    "\n",
    "def Precision(_test_set, _recList):\n",
    "    hit = len(set(_recList).intersection(set(_test_set)))\n",
    "    return hit / float(len(_recList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ugf(scores):\n",
    "    return np.mean([abs(i[0] - i[1]) for i in combinations(scores, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local data\n",
    "listening_df = pd.read_csv('./data/lastfm_2020/listening_events_2020.tsv', header=1, sep='\\t',\n",
    "                           names=['user_id', 'track_id', 'album_id', 'timestamp'])\n",
    "user_df = pd.read_csv('./data/lastfm_2020/users_2020.tsv', header=1, sep='\\t',\n",
    "                     names=['user_id', 'country', 'age', 'gender', 'creation_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30357785, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listening_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15257, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "listening_users = listening_df['user_id'].unique()\n",
    "filed_users = user_df['user_id'].unique()\n",
    "\n",
    "for id in listening_users:\n",
    "    if id not in filed_users:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user with id 2 is not in the `user_df`, so we delete their record from `listening_df` as well.\n",
    "listening_df = listening_df[listening_df['user_id'] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out users with interactions <= 10\n",
    "user_counts = listening_df['user_id'].value_counts()\n",
    "count_filtered_users = user_counts[user_counts > 10]\n",
    "count_filtered_users = count_filtered_users.index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10407, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out users with age=-1 and users with interactions <= 10\n",
    "filtered_user_df = user_df[(user_df['age'] != -1) & (user_df['user_id'].isin(count_filtered_users))].reset_index()\n",
    "filtered_user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the users into three age groups:\n",
    "# ( ,20], (20, 30], (30, )\n",
    "group_one_user_df = filtered_user_df[filtered_user_df['age'] <= 20]\n",
    "group_two_user_df = filtered_user_df[(filtered_user_df['age'] > 20) & (filtered_user_df['age'] <= 30)]\n",
    "group_thr_user_df = filtered_user_df[filtered_user_df['age'] > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in each group:\n",
      "0-20:\t2528\n",
      "20-30:\t6075\n",
      "30-:\t1804\n"
     ]
    }
   ],
   "source": [
    "print('Number of users in each group:')\n",
    "print(f'0-20:\\t{group_one_user_df.shape[0]}')\n",
    "print(f'20-30:\\t{group_two_user_df.shape[0]}')\n",
    "print(f'30-:\\t{group_thr_user_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21903945, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the records from filtered users\n",
    "filtered_listening_df = listening_df.merge(filtered_user_df, on='user_id')\n",
    "filtered_listening_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_mat(df, user_n, item_n, user_id_to_iid, item_id_to_iid):\n",
    "    \"\"\"\n",
    "    Convert DataFrame to sparse matrix.\n",
    "\n",
    "    Arg:\n",
    "        df: DataFrame, ratings dataframe with user_id, movie_id and rating\n",
    "\n",
    "    Return:\n",
    "        mat: scipy.sparse.csr_matrix, sparse ratings matrix with rows being users and cols being items\n",
    "    \"\"\"\n",
    "    \n",
    "    mat = sparse.lil_matrix((user_n, item_n))\n",
    "    for _, row in df.iterrows():\n",
    "        user_id = int(row[0])\n",
    "        item_id = int(row[1])\n",
    "        user_iid = user_id_to_iid[user_id]\n",
    "        item_iid = item_id_to_iid[item_id]\n",
    "        mat[user_iid, item_iid] = 1\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_n = filtered_listening_df['user_id'].nunique()\n",
    "item_n = filtered_listening_df['track_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = filtered_listening_df['user_id'].unique()\n",
    "item_ids = filtered_listening_df['track_id'].unique()\n",
    "\n",
    "user_id_to_iid = {user_ids[i]:i for i in range(len(user_ids))}\n",
    "user_iid_to_id = {i:user_ids[i] for i in range(len(user_ids))}\n",
    "\n",
    "item_id_to_iid = {item_ids[i]:i for i in range(len(item_ids))}\n",
    "item_iid_to_id = {i:item_ids[i] for i in range(len(item_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_one_user_ids = group_one_user_df['user_id'].unique()\n",
    "group_two_user_ids = group_two_user_df['user_id'].unique()\n",
    "group_thr_user_ids = group_thr_user_df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(filtered_listening_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = df_to_mat(train_df, user_n, item_n, user_id_to_iid, item_id_to_iid)\n",
    "train_mat = train_mat.tocsr()\n",
    "\n",
    "test_mat = df_to_mat(test_df, user_n, item_n, user_id_to_iid, item_id_to_iid)\n",
    "test_mat = test_mat.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c42c8a569204b838de98031724a90fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf = implicit.als.AlternatingLeastSquares(factors=100, regularization=0.01, alpha=1.0)\n",
    "mf.fit(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_one_recall = []\n",
    "for user_id in group_one_user_ids:\n",
    "    user_iid = user_id_to_iid[user_id]\n",
    "    \n",
    "    test_item_iids = list(np.argwhere(test_mat[user_iid] > 0)[:, 1])\n",
    "    test_item_ids = [item_iid_to_id[iid] for iid in test_item_iids]\n",
    "\n",
    "    if len(test_item_ids) > 0:\n",
    "        top_item_iids = list(mf.recommend(user_iid, train_mat[user_iid], N=10, filter_already_liked_items=True)[0])\n",
    "        top_item_ids = [item_iid_to_id[iid] for iid in top_item_iids]\n",
    "\n",
    "        recall = Recall(test_item_ids, top_item_ids)\n",
    "        group_one_recall.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08964328113516874"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(group_one_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08231488673900933\n"
     ]
    }
   ],
   "source": [
    "group_two_recall = []\n",
    "for user_id in group_two_user_ids:\n",
    "    user_iid = user_id_to_iid[user_id]\n",
    "    \n",
    "    test_item_iids = list(np.argwhere(test_mat[user_iid] > 0)[:, 1])\n",
    "    test_item_ids = [item_iid_to_id[iid] for iid in test_item_iids]\n",
    "\n",
    "    if len(test_item_ids) > 0:\n",
    "        top_item_iids = list(mf.recommend(user_iid, train_mat[user_iid], N=10, filter_already_liked_items=True)[0])\n",
    "        top_item_ids = [item_iid_to_id[iid] for iid in top_item_iids]\n",
    "\n",
    "        recall = Recall(test_item_ids, top_item_ids)\n",
    "        group_two_recall.append(recall)\n",
    "print(np.average(group_two_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08147994083934183\n"
     ]
    }
   ],
   "source": [
    "group_thr_recall = []\n",
    "for user_id in group_thr_user_ids:\n",
    "    user_iid = user_id_to_iid[user_id]\n",
    "    \n",
    "    test_item_iids = list(np.argwhere(test_mat[user_iid] > 0)[:, 1])\n",
    "    test_item_ids = [item_iid_to_id[iid] for iid in test_item_iids]\n",
    "\n",
    "    if len(test_item_ids) > 0:\n",
    "        top_item_iids = list(mf.recommend(user_iid, train_mat[user_iid], N=10, filter_already_liked_items=True)[0])\n",
    "        top_item_ids = [item_iid_to_id[iid] for iid in top_item_iids]\n",
    "\n",
    "        recall = Recall(test_item_ids, top_item_ids)\n",
    "        group_thr_recall.append(recall)\n",
    "print(np.average(group_thr_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_scores = [np.average(group_one_recall), np.average(group_two_recall), np.average(group_thr_recall)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005442226863884607"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ugf(cf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sipei/micromamba/envs/fairness_env/lib/python3.8/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855b322c5f844996ae240355df0dc3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77188af96e214cc2a4c437acb74470f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc26977156043ac8607ad4eaf9ed191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d2b0a84f6046beb3b3b56e1eeb3cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2bea43fc1e4bc68c02e300d700b865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad63fa7371044db8ef4bd28b20a3021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931c3124aeaa4fe08ff7449dfb04d7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c7692772424aafa0e4425582e1bd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e913b539f44f54b0c4f08a964be1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec844937e644870a4eaaaac580349ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_ugfs = []\n",
    "n_epochs = 10\n",
    "for _ in range(n_epochs):\n",
    "    train_df, test_df = train_test_split(filtered_listening_df, test_size=0.2)\n",
    "    train_mat = df_to_mat(train_df, user_n, item_n, user_id_to_iid, item_id_to_iid)\n",
    "    train_mat = train_mat.tocsr()\n",
    "\n",
    "    test_mat = df_to_mat(test_df, user_n, item_n, user_id_to_iid, item_id_to_iid)\n",
    "    test_mat = test_mat.tocsr()\n",
    "\n",
    "    mf = implicit.als.AlternatingLeastSquares(factors=100, regularization=0.01, alpha=1.0)\n",
    "    mf.fit(train_mat)\n",
    "\n",
    "    group_one_recall = []\n",
    "    for user_id in group_one_user_ids:\n",
    "        user_iid = user_id_to_iid[user_id]\n",
    "    \n",
    "        test_item_iids = list(np.argwhere(test_mat[user_iid] > 0)[:, 1])\n",
    "        test_item_ids = [item_iid_to_id[iid] for iid in test_item_iids]\n",
    "\n",
    "        if len(test_item_ids) > 0:\n",
    "            top_item_iids = list(mf.recommend(user_iid, train_mat[user_iid], N=10, filter_already_liked_items=True)[0])\n",
    "            top_item_ids = [item_iid_to_id[iid] for iid in top_item_iids]\n",
    "\n",
    "            recall = Recall(test_item_ids, top_item_ids)\n",
    "            group_one_recall.append(recall)\n",
    "    \n",
    "    group_two_recall = []\n",
    "    for user_id in group_two_user_ids:\n",
    "        user_iid = user_id_to_iid[user_id]\n",
    "    \n",
    "        test_item_iids = list(np.argwhere(test_mat[user_iid] > 0)[:, 1])\n",
    "        test_item_ids = [item_iid_to_id[iid] for iid in test_item_iids]\n",
    "\n",
    "        if len(test_item_ids) > 0:\n",
    "            top_item_iids = list(mf.recommend(user_iid, train_mat[user_iid], N=10, filter_already_liked_items=True)[0])\n",
    "            top_item_ids = [item_iid_to_id[iid] for iid in top_item_iids]\n",
    "\n",
    "            recall = Recall(test_item_ids, top_item_ids)\n",
    "            group_two_recall.append(recall)\n",
    "\n",
    "    group_thr_recall = []\n",
    "    for user_id in group_thr_user_ids:\n",
    "        user_iid = user_id_to_iid[user_id]\n",
    "    \n",
    "        test_item_iids = list(np.argwhere(test_mat[user_iid] > 0)[:, 1])\n",
    "        test_item_ids = [item_iid_to_id[iid] for iid in test_item_iids]\n",
    "\n",
    "        if len(test_item_ids) > 0:\n",
    "            top_item_iids = list(mf.recommend(user_iid, train_mat[user_iid], N=10, filter_already_liked_items=True)[0])\n",
    "            top_item_ids = [item_iid_to_id[iid] for iid in top_item_iids]\n",
    "\n",
    "            recall = Recall(test_item_ids, top_item_ids)\n",
    "            group_thr_recall.append(recall)\n",
    "    \n",
    "    cf_scores = [np.average(group_one_recall), np.average(group_two_recall), np.average(group_thr_recall)]\n",
    "    cf_ugfs.append(ugf(cf_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004380657234075908"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cf_ugfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012795994106208355"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(cf_ugfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_json_lst = []\n",
    "with open('./data/lastfm/tags.json', 'r', encoding='utf-8') as f:\n",
    "    for obj in f:\n",
    "        track_dict = json.loads(obj)\n",
    "        track_json_lst.append(track_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_tags_lst = []\n",
    "for obj in track_json_lst:\n",
    "    track_id = obj['i']\n",
    "    tags = list(obj['tags'].keys())[:10]    # use the first 10 tags\n",
    "    track_tags_lst.append([track_id, tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = pd.DataFrame(track_tags_lst, columns=['track_id', 'tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_recommend(user_id, topk, knn, train_df, X, item_n, item_id_to_iid, item_iid_to_id):\n",
    "    sorted_rated_before = np.asarray(train_df[(train_df['user_id']==user_id)]['track_id'].value_counts().index)\n",
    "    \n",
    "    if sorted_rated_before.size > 0:\n",
    "\n",
    "        raw_recommends = {}\n",
    "        for item_id in sorted_rated_before:\n",
    "            item_iid = item_id_to_iid[item_id]\n",
    "            distances, indices = knn.kneighbors(X[item_iid], \n",
    "                                                n_neighbors=topk+1)\n",
    "            sorted_pairs = sorted(list(zip(indices.squeeze().tolist(),\n",
    "                                           distances.squeeze().tolist())),\n",
    "                                  key=lambda x: x[1])\n",
    "            raw_recommends[item_iid] = sorted_pairs \n",
    "        \n",
    "        top_item_ids = []\n",
    "        pos = 0\n",
    "        while True:\n",
    "            for item_id in sorted_rated_before:\n",
    "                item_iid = item_id_to_iid[item_id]\n",
    "                next_neighbor_iid = raw_recommends[item_iid][pos][0]\n",
    "                next_neighbor_id = item_iid_to_id[next_neighbor_iid]\n",
    "                if next_neighbor_id not in sorted_rated_before:\n",
    "                    top_item_ids.append(next_neighbor_id)\n",
    "                if len(top_item_ids) > topk - 1:\n",
    "                    return (user_id, np.array(top_item_ids))\n",
    "            \n",
    "            pos += 1\n",
    "    else:\n",
    "\n",
    "        top_item_iids = random.sample(list(range(0, item_n)), topk)\n",
    "        top_item_ids = [item_iid_to_id[iid] for iid in top_item_iids]\n",
    "        return (user_id, np.asarray(top_item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_evaluate(test_user_ids, knn, X, train_df, test_df, item_n):\n",
    "\n",
    "    r = []\n",
    "    for user_id in test_user_ids:\n",
    "        test_item_ids = np.asarray(test_df[test_df['user_id']==user_id]['track_id'].unique())\n",
    "        \n",
    "        if len(test_item_ids) > 0:\n",
    "            top_item_ids = list(cb_recommend(user_id, 10, knn, train_df, X, item_n, item_id_to_iid, item_iid_to_id)[1])\n",
    "            recall = Recall(test_item_ids, top_item_ids)\n",
    "            r.append(recall)\n",
    "    \n",
    "    return np.average(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_listening_df = pd.merge(listening_df, tag_df, on='track_id')\n",
    "cb_ugfs = []\n",
    "for _ in range(n_epochs):\n",
    "    sampled_tagged_listening_df = tagged_listening_df.sample(frac=0.2, ignore_index=True)\n",
    "\n",
    "    # filter out users with interactions <= 10\n",
    "    user_counts = sampled_tagged_listening_df['user_id'].value_counts()\n",
    "    count_filtered_users = user_counts[user_counts > 10]\n",
    "    count_filtered_users = count_filtered_users.index.to_numpy()\n",
    "\n",
    "    # filter out users with age=-1 and users with interactions <= 10\n",
    "    filtered_user_df = user_df[(user_df['age'] != -1) & (user_df['user_id'].isin(count_filtered_users))].reset_index()\n",
    "\n",
    "    # group the users into three age groups:\n",
    "    # ( ,20], (20, 30], (30, )\n",
    "    group_one_user_df = filtered_user_df[filtered_user_df['age'] <= 20]\n",
    "    group_two_user_df = filtered_user_df[(filtered_user_df['age'] > 20) & (filtered_user_df['age'] <= 30)]\n",
    "    group_thr_user_df = filtered_user_df[filtered_user_df['age'] > 30]\n",
    "    \n",
    "    # only keep the records from filtered users\n",
    "    filtered_tagged_listening_df = sampled_tagged_listening_df.merge(filtered_user_df, on='user_id')\n",
    "\n",
    "    user_n = filtered_tagged_listening_df['user_id'].nunique()\n",
    "    item_n = filtered_tagged_listening_df['track_id'].nunique()\n",
    "\n",
    "    user_ids = filtered_tagged_listening_df['user_id'].unique()\n",
    "    item_ids = filtered_tagged_listening_df['track_id'].unique()\n",
    "\n",
    "    item_id_to_iid = {item_ids[i]:i for i in range(len(item_ids))}\n",
    "    item_iid_to_id = {i:item_ids[i] for i in range(len(item_ids))}\n",
    "\n",
    "    group_one_user_ids = group_one_user_df['user_id'].unique()\n",
    "    group_two_user_ids = group_two_user_df['user_id'].unique()\n",
    "    group_thr_user_ids = group_thr_user_df['user_id'].unique()\n",
    "    # print(f'number of group one users: {group_one_user_ids.shape}')\n",
    "    # print(f'number of group two users: {group_two_user_ids.shape}')\n",
    "    # print(f'number of group thr users: {group_thr_user_ids.shape}')\n",
    "\n",
    "    filtered_tag_df = filtered_tagged_listening_df.drop_duplicates(subset=['track_id'])[['track_id', 'tags']]\n",
    "\n",
    "    tf = TfidfVectorizer(analyzer = lambda x: (g for g in x))\n",
    "    X_tfidf = tf.fit_transform(filtered_tag_df['tags'])\n",
    "\n",
    "    knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=10, n_jobs=-1)\n",
    "    knn.fit(X_tfidf)\n",
    "\n",
    "    train_df, test_df = train_test_split(filtered_tagged_listening_df, test_size=0.2)\n",
    "\n",
    "    all_group_one_recall = []\n",
    "    all_group_two_recall = []\n",
    "    all_group_thr_recall = []\n",
    "\n",
    "    n_iters = 1\n",
    "    for _ in range(n_iters):\n",
    "\n",
    "        test_group_one_user_ids = np.random.choice(group_one_user_ids, size=50, replace=False)\n",
    "        # test_group_one_user_ids = np.random.choice(group_one_user_ids, size=10, replace=False)\n",
    "        test_group_two_user_ids = np.random.choice(group_two_user_ids, size=50, replace=False)\n",
    "        test_group_thr_user_ids = np.random.choice(group_thr_user_ids, size=50, replace=False)\n",
    "\n",
    "        group_one_recall = sample_evaluate(test_group_one_user_ids, knn, X_tfidf, train_df, test_df, item_n)\n",
    "        group_two_recall = sample_evaluate(test_group_two_user_ids, knn, X_tfidf, train_df, test_df, item_n)\n",
    "        group_thr_recall = sample_evaluate(test_group_thr_user_ids, knn, X_tfidf, train_df, test_df, item_n)\n",
    "\n",
    "        all_group_one_recall.append(group_one_recall)\n",
    "        all_group_two_recall.append(group_two_recall)\n",
    "        all_group_thr_recall.append(group_thr_recall)\n",
    "    \n",
    "    cb_scores = [np.mean(all_group_one_recall),\n",
    "                np.mean(all_group_two_recall),\n",
    "                np.mean(all_group_thr_recall)]\n",
    "    cb_ugfs.append(ugf(cb_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006004988662131519"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cb_ugfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024381067530907215"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(cb_ugfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_listening_df = pd.merge(listening_df, tag_df, on='track_id')\n",
    "tagged_listening_df = tagged_listening_df.sample(frac=0.2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out users with interactions <= 10\n",
    "user_counts = tagged_listening_df['user_id'].value_counts()\n",
    "count_filtered_users = user_counts[user_counts > 10]\n",
    "count_filtered_users = count_filtered_users.index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9554, 6)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out users with age=-1 and users with interactions <= 10\n",
    "filtered_user_df = user_df[(user_df['age'] != -1) & (user_df['user_id'].isin(count_filtered_users))].reset_index()\n",
    "filtered_user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the users into three age groups:\n",
    "# ( ,20], (20, 30], (30, )\n",
    "group_one_user_df = filtered_user_df[filtered_user_df['age'] <= 20]\n",
    "group_two_user_df = filtered_user_df[(filtered_user_df['age'] > 20) & (filtered_user_df['age'] <= 30)]\n",
    "group_thr_user_df = filtered_user_df[filtered_user_df['age'] > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in each group:\n",
      "0-20:\t2373\n",
      "20-30:\t5553\n",
      "30-:\t1628\n"
     ]
    }
   ],
   "source": [
    "print('Number of users in each group:')\n",
    "print(f'0-20:\\t{group_one_user_df.shape[0]}')\n",
    "print(f'20-30:\\t{group_two_user_df.shape[0]}')\n",
    "print(f'30-:\\t{group_thr_user_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2428497, 10)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the records from filtered users\n",
    "filtered_tagged_listening_df = tagged_listening_df.merge(filtered_user_df, on='user_id')\n",
    "filtered_tagged_listening_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_n = filtered_tagged_listening_df['user_id'].nunique()\n",
    "item_n = filtered_tagged_listening_df['track_id'].nunique()\n",
    "\n",
    "user_ids = filtered_tagged_listening_df['user_id'].unique()\n",
    "item_ids = filtered_tagged_listening_df['track_id'].unique()\n",
    "\n",
    "item_id_to_iid = {item_ids[i]:i for i in range(len(item_ids))}\n",
    "item_iid_to_id = {i:item_ids[i] for i in range(len(item_ids))}\n",
    "\n",
    "group_one_user_ids = group_one_user_df['user_id'].unique()\n",
    "group_two_user_ids = group_two_user_df['user_id'].unique()\n",
    "group_thr_user_ids = group_thr_user_df['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tag_df = filtered_tagged_listening_df.drop_duplicates(subset=['track_id'])[['track_id', 'tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer = lambda x: (g for g in x))\n",
    "X_tfidf = tf.fit_transform(filtered_tag_df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_jobs=-1, n_neighbors=10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=10, n_jobs=-1)\n",
    "knn.fit(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(filtered_tagged_listening_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level one user recall: 0.010951743481863964\n",
      "Level two user recall: 0.010648280688360849\n",
      "Level thr user recall: 0.012536002304147467\n"
     ]
    }
   ],
   "source": [
    "all_group_one_recall = []\n",
    "all_group_two_recall = []\n",
    "all_group_thr_recall = []\n",
    "\n",
    "n_iters = 1\n",
    "for _ in range(n_iters):\n",
    "\n",
    "    test_group_one_user_ids = np.random.choice(group_one_user_ids, size=500, replace=False)\n",
    "    test_group_two_user_ids = np.random.choice(group_two_user_ids, size=500, replace=False)\n",
    "    test_group_thr_user_ids = np.random.choice(group_thr_user_ids, size=500, replace=False)\n",
    "\n",
    "    group_one_recall = sample_evaluate(test_group_one_user_ids, knn, X_tfidf, train_df, test_df, item_n)\n",
    "    group_two_recall = sample_evaluate(test_group_two_user_ids, knn, X_tfidf, train_df, test_df, item_n)\n",
    "    group_thr_recall = sample_evaluate(test_group_thr_user_ids, knn, X_tfidf, train_df, test_df, item_n)\n",
    "\n",
    "    all_group_one_recall.append(group_one_recall)\n",
    "    all_group_two_recall.append(group_two_recall)\n",
    "    all_group_thr_recall.append(group_thr_recall)\n",
    "    \n",
    "    print(f'Level one user recall: {group_one_recall}')\n",
    "    print(f'Level two user recall: {group_two_recall}')\n",
    "    print(f'Level thr user recall: {group_thr_recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_scores = [np.mean(all_group_one_recall),\n",
    "             np.mean(all_group_two_recall),\n",
    "             np.mean(all_group_thr_recall)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012584810771910787"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ugf(cb_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
